{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xe-a8yZMWTf2",
        "outputId": "d2e00e37-2850-43dc-90f0-7c4ed8600d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting qwen-vl-utils\n",
            "  Downloading qwen_vl_utils-0.0.11-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting captum\n",
            "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Collecting pillow\n",
            "  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: huggingface_hub[hf_xet] in /usr/local/lib/python3.11/dist-packages (0.33.2)\n",
            "Collecting huggingface_hub[hf_xet]\n",
            "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.8.1)\n",
            "Collecting av (from qwen-vl-utils)\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_xet]) (1.1.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qwen_vl_utils-0.0.11-py3-none-any.whl (7.6 kB)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=6dd8c0346b1d6bb15eaa34ed3f5bdbba542388c94926e49400c467b8d2382d85\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fsspec, av, rouge_score, qwen-vl-utils, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, nvidia-cusolver-cu12, matplotlib, transformers, datasets, evaluate, captum, bitsandbytes, bert_score\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.33.2\n",
            "    Uninstalling huggingface-hub-0.33.2:\n",
            "      Successfully uninstalled huggingface-hub-0.33.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.1\n",
            "    Uninstalling transformers-4.53.1:\n",
            "      Successfully uninstalled transformers-4.53.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-15.0.0 bert_score-0.3.13 bitsandbytes-0.46.1 captum-0.8.0 datasets-4.0.0 evaluate-0.4.5 fsspec-2025.3.0 huggingface_hub-0.33.4 matplotlib-3.10.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pillow-11.3.0 qwen-vl-utils-0.0.11 rouge_score-0.1.2 transformers-4.53.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              },
              "id": "09e0b750d47142bca406792bcf5d4604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/salaniz/pycocoevalcap.git\n",
            "  Cloning https://github.com/salaniz/pycocoevalcap.git to /tmp/pip-req-build-5hzso47h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/salaniz/pycocoevalcap.git /tmp/pip-req-build-5hzso47h\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# %% [markdown]\n",
        "# # 合并 Qwen2-VL 多任务消融实验与 Grad-CAM 可视化 Notebook\n",
        "# 本 Notebook 包含：\n",
        "# 1. 环境依赖安装\n",
        "# 2. Google Drive HF 缓存配置\n",
        "# 3. 库导入与模型/数据处理函数定义\n",
        "# 4. 数据加载与处理\n",
        "# 5. 评估回调与指标定义\n",
        "# 6. 训练 & 消融实验\n",
        "# 7. 训练后评估\n",
        "# 8. Grad-CAM 可视化\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 1. 环境依赖安装\n",
        "!pip install --upgrade transformers datasets peft evaluate qwen-vl-utils bitsandbytes captum matplotlib pillow rouge_score huggingface_hub[hf_xet] bert_score\n",
        "!pip install git+https://github.com/salaniz/pycocoevalcap.git\n",
        "!pip install pytorch_grad_cam\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. 库导入与模型/数据处理函数定义\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration, BitsAndBytesConfig, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import evaluate\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from pycocoevalcap.cider.cider import Cider\n",
        "from bert_score import BERTScorer\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "# LoRA + 多任务分类 Head\n",
        "class Qwen2VLWithClassifier(torch.nn.Module):\n",
        "    def __init__(self, pretrained_qwen, num_labels=1, cls_loss_weight=1.0):\n",
        "        super().__init__()\n",
        "        self.qwen = pretrained_qwen\n",
        "        self.cls_loss_weight = cls_loss_weight\n",
        "        hidden_size = self.qwen.config.hidden_size\n",
        "        self.classifier = torch.nn.Linear(hidden_size, num_labels)\n",
        "        self.cls_loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, pixel_values=None, input_ids=None, attention_mask=None, labels=None, cls_labels=None, output_attentions=True, return_dict=True, **kwargs):\n",
        "        # pop 多余参数\n",
        "        for k in [\"num_items_in_batch\",\"pixel_mask\",\"use_cache\",\"image_grid_thw\"]:\n",
        "            kwargs.pop(k, None)\n",
        "        gen_out = self.qwen(pixel_values=pixel_values, input_ids=input_ids, attention_mask=attention_mask, labels=labels, output_attentions=output_attentions, return_dict=return_dict)\n",
        "        # 分类 head\n",
        "        vision_feats = None\n",
        "        for m in self.qwen.modules():\n",
        "            if hasattr(m, \"get_image_features\"): vision_feats = m.get_image_features(pixel_values.to(self.qwen.device)); break\n",
        "        cls_logits = self.classifier(vision_feats)\n",
        "        # 计算联合 loss\n",
        "        gen_loss = gen_out.loss if labels is not None else None\n",
        "        cls_loss = self.cls_loss_fn(cls_logits.view(-1), cls_labels.view(-1)) if cls_labels is not None else None\n",
        "        total_loss = None\n",
        "        if gen_loss is not None and cls_loss is not None:\n",
        "            total_loss = gen_loss + self.cls_loss_weight * cls_loss\n",
        "        elif gen_loss is not None:\n",
        "            total_loss = gen_loss\n",
        "        elif cls_loss is not None:\n",
        "            total_loss = cls_loss\n",
        "        return {\"loss\": total_loss, \"gen_logits\": gen_out.logits, \"cls_logits\": cls_logits}\n",
        "\n",
        "# Collate 函数\n",
        "def collate_fn_train(examples):\n",
        "    processor = collate_fn_train.processor\n",
        "    texts, imgs, cls_lbs = [], [], []\n",
        "    for ex in examples:\n",
        "        prompt = random.choice(collate_fn_train.prompts)\n",
        "        img = ex[\"image\"]\n",
        "        if isinstance(img, dict): img = Image.open(img[\"path\"]).convert(\"RGB\")\n",
        "        elif not isinstance(img, Image.Image): img = Image.open(img).convert(\"RGB\")\n",
        "        msgs = [{\"role\":\"user\",\"content\":[{\"type\":\"image\",\"image\":img},{\"type\":\"text\",\"text\":prompt}]}, {\"role\":\"assistant\",\"content\":ex[\"caption\"]}]\n",
        "        txt = processor.apply_chat_template(msgs, tokenize=False, add_generation_prompt=False)\n",
        "        texts.append(txt); imgs.append(img); cls_lbs.append(ex[\"cls_label\"])\n",
        "    batch = processor(text=texts, images=imgs, padding=True, return_tensors=\"pt\")\n",
        "    labels = batch.input_ids.clone()\n",
        "    tok = processor.tokenizer\n",
        "    vs, ve, vp, pad = tok.convert_tokens_to_ids([\"<|vision_start|>\",\"<|vision_end|>\",\"<|image_pad|>\\n\"] ) + [tok.pad_token_id]\n",
        "    mask = (labels==vs)|(labels==ve)|(labels==vp)|(labels==pad)\n",
        "    labels[mask] = -100\n",
        "    batch[\"labels\"] = labels\n",
        "    batch[\"cls_labels\"] = torch.tensor(cls_lbs, dtype=torch.float)\n",
        "    return batch\n",
        "\n",
        "def collate_fn_eval(examples):\n",
        "    processor = collate_fn_train.processor\n",
        "    texts, imgs, caps, cls_lbs = [], [], [], []\n",
        "    for ex in examples:\n",
        "        prompt = random.choice(collate_fn_train.prompts)\n",
        "        img = ex[\"image\"]\n",
        "        if isinstance(img, dict): img = Image.open(img[\"path\"]).convert(\"RGB\")\n",
        "        elif not isinstance(img, Image.Image): img = Image.open(img).convert(\"RGB\")\n",
        "        msgs = [{\"role\":\"user\",\"content\":[{\"type\":\"image\",\"image\":img},{\"type\":\"text\",\"text\":prompt}]}]\n",
        "        txt = processor.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
        "        texts.append(txt); imgs.append(img); caps.append(ex[\"caption\"]); cls_lbs.append(ex[\"cls_label\"])\n",
        "    batch = processor(text=texts, images=imgs, padding=True, return_tensors=\"pt\")\n",
        "    batch[\"captions\"] = caps; batch[\"cls_labels\"] = cls_lbs\n",
        "    return batch\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. 加载模型、Processor 与 Prompt 池\n",
        "repo_id = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
        "processor = AutoProcessor.from_pretrained(repo_id, trust_remote_code=True)\n",
        "bnb_cfg = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16)\n",
        "base_model = Qwen2VLForConditionalGeneration.from_pretrained(repo_id, trust_remote_code=True, quantization_config=bnb_cfg, device_map=\"auto\")\n",
        "peft_cfg = LoraConfig(r=32, lora_alpha=32, target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"], lora_dropout=0.05, bias=\"none\", task_type=\"CAUSAL_LM\")\n",
        "base_model = get_peft_model(base_model, peft_cfg)\n",
        "wrapped_model = Qwen2VLWithClassifier(pretrained_qwen=base_model)\n",
        "\n",
        "# Prompt 池\n",
        "collate_fn_train.processor = processor\n",
        "collate_fn_train.prompts = [\n",
        "    \"Q: Does this image support the statement? Explain.\",\n",
        "    \"Is the description accurate? Why or why not?\"\n",
        "    # ... 可添加更多变体\n",
        "]\n",
        "collate_fn_train = collate_fn_train; collate_fn_eval = collate_fn_eval\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 5. 加载数据集 & 转为 Dataset\n",
        "from datasets import load_dataset\n",
        "import itertools\n",
        "raw_train = load_dataset(\"J1mb0o/e-snli-ve\", split=\"train\", streaming=True)\n",
        "raw_dev   = load_dataset(\"J1mb0o/e-snli-ve\", split=\"dev\", streaming=True)\n",
        "\n",
        "def preprocess(ex): return {\"image\":ex[\"image\"], \"caption\":ex[\"hypothesis\"], \"cls_label\": (1.0 if ex[\"gold_label\"]==0 else 0.0)}\n",
        "train_list = [preprocess(ex) for ex in itertools.islice(raw_train, 80)]\n",
        "eval_list  = [preprocess(ex) for ex in itertools.islice(raw_dev, 20)]\n",
        "train_ds = Dataset.from_list(train_list)\n",
        "eval_ds  = Dataset.from_list(eval_list)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. 定义评估回调 & 指标\n",
        "_smooth = SmoothingFunction().method1\n",
        "rouge  = evaluate.load(\"rouge\")\n",
        "bleu   = evaluate.load(\"bleu\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "cider  = Cider()\n",
        "berts  = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "from transformers import TrainerCallback\n",
        "class LowMemEvalCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        device = wrapped_model.qwen.device\n",
        "        all_pred, all_ref = [], []\n",
        "        cls_corr, cls_tot = 0,0\n",
        "        loader = torch.utils.data.DataLoader(eval_ds, batch_size=4, collate_fn=collate_fn_eval)\n",
        "        wrapped_model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in loader:\n",
        "                inputs = {k:v.to(device) for k,v in batch.items() if k in [\"pixel_values\",\"input_ids\",\"attention_mask\"]}\n",
        "                if \"image_grid_thw\" in batch: inputs[\"image_grid_thw\"]=batch[\"image_grid_thw\"].to(device)\n",
        "                outs = wrapped_model.qwen.generate(**inputs, max_new_tokens=100, num_beams=4)\n",
        "                txts = processor.batch_decode(outs[:,inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "                all_pred.extend(txts); all_ref.extend(batch[\"captions\"])\n",
        "                # 分类\n",
        "                fwd = wrapped_model(pixel_values=batch[\"pixel_values\"].to(device), input_ids=batch[\"input_ids\"].to(device), attention_mask=batch[\"attention_mask\"].to(device), cls_labels=None)\n",
        "                probs = torch.sigmoid(fwd[\"cls_logits\"].view(-1))>0.5\n",
        "                golds = batch[\"cls_labels\"]\n",
        "                for p,g in zip(probs.cpu(), golds): cls_corr += (p.int()==int(g)); cls_tot+=1\n",
        "        # 打印指标\n",
        "        print(f\"Epoch {int(state.epoch)}: ROUGE-L {rouge.compute(predictions=all_pred,references=all_ref,use_stemmer=True)['rougeL']:.4f}, BLEU {bleu.compute(predictions=all_pred,references=[[r] for r in all_ref])['bleu']:.4f}, ACC {cls_corr/cls_tot:.4f}\")\n",
        "        return control\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 7. 训练 & 消融实验\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./output\", num_train_epochs=5, per_device_train_batch_size=4, per_device_eval_batch_size=4,\n",
        "    learning_rate=5e-5, warmup_steps=20, weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\", eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
        "    remove_unused_columns=False, predict_with_generate=False\n",
        ")\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=wrapped_model, args=training_args,\n",
        "    train_dataset=train_ds, eval_dataset=eval_ds,\n",
        "    data_collator=collate_fn_train, callbacks=[LowMemEvalCallback()]\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 8. Grad-CAM 可视化\n",
        "# 取一张样例图\n",
        "ex = eval_ds[0]\n",
        "img = ex['image']\n",
        "if isinstance(img, dict): img = Image.open(img['path']).convert('RGB')\n",
        "elif not isinstance(img, Image.Image): img = Image.open(img).convert('RGB')\n",
        "original_size = img.size\n",
        "\n",
        "prompt = random.choice(collate_fn_train.prompts)\n",
        "msgs = [{\"role\":\"user\",\"content\":[{\"type\":\"image\",\"image\":img},{\"type\":\"text\",\"text\":prompt}]}]\n",
        "inputs = processor(text=processor.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True), images=[img], padding=True, return_tensors='pt')\n",
        "\n",
        "# 前向获得特征图\n",
        "wrapped = wrapped_model.qwen\n",
        "vision = wrapped.model.visual\n",
        "cam = GradCAM(model=wrapped, target_layers=[vision.patch_embed.proj], use_cuda=torch.cuda.is_available())\n",
        "\n",
        "grayscale_cam = cam(input_tensor=inputs['pixel_values'].to(wrapped.device))[0]\n",
        "heatmap = np.uint8(255 * grayscale_cam)\n",
        "heatmap = Image.fromarray(heatmap).resize(original_size)\n",
        "\n",
        "# 可视化\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1); plt.imshow(img); plt.axis('off'); plt.title('Original')\n",
        "plt.subplot(1,2,2); plt.imshow(img); plt.imshow(np.array(heatmap), cmap='jet', alpha=0.5); plt.axis('off'); plt.title('Grad-CAM')\n",
        "plt.show()\n"
      ]
    }
  ]
}